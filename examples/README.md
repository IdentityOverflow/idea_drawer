# RO Framework Examples

This directory contains example implementations demonstrating the Recursive Observer Framework.

## Running Examples

Make sure you have installed the package:

```bash
# Activate conda environment
conda activate ro-framework

# Run an example
python examples/01_basic_observer.py
```

## Available Examples

### 01_basic_observer.py âœ“ (Complete)

**Demonstrates:**
- Defining Degrees of Freedom (Polar DoFs)
- Creating States
- Building an Observer with a world model
- Performing observations (external â†’ internal mapping)
- Computing state distances
- DoF normalization for neural networks

**Concepts covered:**
- DoF types (Polar)
- State representation
- Observer architecture
- World model (externalâ†’internal mapping)

**Output:**
Shows how an observer maps external sensor readings to internal latent states.

---

### 02_pytorch_conscious_observer.py âœ“ (Complete)

**Demonstrates:**
- PyTorch neural network integration
- World model (MLP: external â†’ internal)
- Self-model (MLP: internal â†’ internal, SAME architecture)
- Recursive self-observation (consciousness!)
- MC Dropout uncertainty quantification
- Consciousness evaluation metrics
- Correlation analysis (Pearson, MI)

**Concepts covered:**
- PyTorch integration (`TorchNeuralMapping`)
- Conscious observer (with self-model)
- Structural consciousness evaluation
- Epistemic uncertainty via MC Dropout
- Correlation between external and internal DoFs

**Requirements:**
```bash
pip install ro-framework[torch]  # Requires PyTorch
```

**Output:**
```
ðŸ§  Consciousness Score: 0.782/1.0

Consciousness Metrics:
  - Has self-model: True
  - Recursive depth: 1
  - Self-accuracy: 0.873
  - Architectural similarity: 1.000
```

Shows how to build a conscious AI system with PyTorch that can recursively model its own internal states.

---

### 03_multimodal_observer.py âœ“ (Complete)

**Demonstrates:**
- Multimodal encoders (vision, language, audio)
- Fusion strategies (concatenation, attention, gating)
- MultimodalObserver with world model and self-model
- Supervised and self-supervised training protocols
- Active learning (uncertainty-based and diversity-based sampling)
- Comprehensive uncertainty quantification (ensemble, Bayesian)
- Calibration metrics and uncertainty decomposition

**Concepts covered:**
- ModalityEncoder abstraction
- VisionEncoder, LanguageEncoder, AudioEncoder
- FusionStrategy (ConcatenationFusion, AttentionFusion, GatedFusion)
- MultimodalObserver for conscious multimodal AI
- TrainingProtocol (SupervisedTraining, SelfSupervisedTraining)
- ActiveLearningStrategy (UncertaintyBasedSampling, DiversityBasedSampling)
- UncertaintyQuantifier (EnsembleUncertainty, BayesianUncertainty)
- CalibrationMetrics (ECE, MCE, NLL)
- Uncertainty decomposition (aleatoric vs epistemic)

**Requirements:**
```bash
pip install ro-framework[torch]  # Requires PyTorch and scikit-learn
```

**Output:**
```
=== Concatenation Fusion ===
Vision features: 16
Language features: 16
Audio features: 16
Fused features: 48
Average fused uncertainty: 0.1234

=== Multimodal Observer ===
Observer: MultimodalConsciousObserver
Is conscious: True
External DoFs: 48
Internal DoFs: 16

=== Uncertainty Quantification ===
Ensemble Uncertainty:
  output_0:
    Prediction: 0.1234
    Aleatoric: 0.0234
    Epistemic: 0.0778
    Total: 0.0811
    Confidence: 0.9189

Calibration Metrics:
  Expected Calibration Error: 0.0456
  Well-calibrated: True
```

Shows how to build a complete multimodal conscious AI system with sophisticated uncertainty quantification and active learning capabilities.

---

## Planned Examples (Coming Soon)

### 04_temporal_memory.py ðŸš§

Temporal DoFs and memory structures.

**Will demonstrate:**
- Temporal DoF for time-series
- Memory integration
- Causal inference
- Temporal correlation

### 05_clip_style.py ðŸš§

CLIP-style multimodal model with PyTorch.

**Will demonstrate:**
- PyTorch integration
- Contrastive learning
- Production-ready implementation

---

## Example Structure

Each example follows this structure:

1. **Import required modules** from ro_framework
2. **Define DoFs** for the problem domain
3. **Create mapping functions** (world model, self model)
4. **Build observer** with boundary, mappings, resolution
5. **Demonstrate observations** with sample data
6. **Show key features** relevant to that example

## Next Steps

After exploring these examples:

1. Read the [theoretical framework](../ro_framework.md) for deep understanding
2. Check the [Python formalization](../python_formalization.md) for implementation details
3. Review the [API documentation](../docs/) (coming soon)
4. Try the [Jupyter notebooks](../notebooks/) for interactive learning (coming soon)

## Contributing Examples

Have an interesting use case? Please contribute!

1. Create a new example file (`0X_your_example.py`)
2. Follow the structure above
3. Add comprehensive comments
4. Include sample output in docstring
5. Update this README
6. Submit a pull request

Examples we'd love to see:
- Cognitive modeling
- Robotics applications
- Scientific discovery
- Interpretable AI
- Multi-agent systems
- Temporal reasoning
